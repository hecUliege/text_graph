{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8d57d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\porch\\.conda\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lib.preprocessingtext import *\n",
    "# from lib.evaluation import * \n",
    "from lib.findSimilaritiesSent import *\n",
    "from lib.io import *\n",
    "from lib.bert import *\n",
    "# from lib.training import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a368dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertClassToNum(y):\n",
    "    return [target_names.index(i) for i in y]\n",
    "    \n",
    "#     Encoder = LabelEncoder()\n",
    "#     return Encoder.fit_transform(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4318d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSentToTFVec(fullX):\n",
    "\n",
    "    # tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, ngram_range=(1, 2), stop_words = 'english')\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, ngram_range=(1, 2))\n",
    "    return tfidf.fit_transform(fullX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673b697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can accept / refuse as soon as possible\n",
      "Capability\n",
      "991\n",
      "i can accept / refuse as soon as possible\n",
      "Label\n",
      "Capability    684\n",
      "Hard-goal      40\n",
      "Soft-goal     177\n",
      "Task           90\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Capability', 'Hard-goal', 'Soft-goal', 'Task']\n",
    "labels = pd.read_excel(r\"..\\data\\us\\\\newDataset\\Clean US Combine.xlsx\", sheet_name='Sheet1')\n",
    "print(labels['UserStory'][0])\n",
    "print(labels['Label'][0])\n",
    "labels_lemma = preProcessing6(labels['UserStory'])\n",
    "features = convertSentToTFVec(labels_lemma)\n",
    "print(len(labels_lemma))\n",
    "print(labels_lemma[0])\n",
    "print(labels.groupby('Label').size())\n",
    "# convert Class into Number\n",
    "labels['Label'] = convertClassToNum(labels['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57fb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(labels, preds, target_names):\n",
    "    metricReport = classification_report(labels, preds, target_names=target_names, zero_division=0, output_dict=True)\n",
    "    return {\n",
    "        # 'Accuracy': metricReport['accuracy'],\n",
    "        'CapP': metricReport[target_names[0]]['precision'],\n",
    "        'CapR': metricReport[target_names[0]]['recall'],              \n",
    "        'CapF1': metricReport[target_names[0]]['f1-score'],\n",
    "        'HGP': metricReport[target_names[1]]['precision'],\n",
    "        'HGR': metricReport[target_names[1]]['recall'],\n",
    "        'HGF1': metricReport[target_names[1]]['f1-score'],\n",
    "        'SGP': metricReport[target_names[2]]['precision'],\n",
    "        'SGR': metricReport[target_names[2]]['recall'],\n",
    "        'SGF1': metricReport[target_names[2]]['f1-score'],\n",
    "        'TP': metricReport[target_names[3]]['precision'],\n",
    "        'TR': metricReport[target_names[3]]['recall'],\n",
    "        'TF1': metricReport[target_names[3]]['f1-score'],\n",
    "    }\n",
    "    \n",
    "def average_dicts(dicts):\n",
    "    result = {}\n",
    "    counts = {}\n",
    "    \n",
    "    # Iterate through each dictionary in the list\n",
    "    for d in dicts:\n",
    "        # Iterate through each key-value pair in the dictionary\n",
    "        for key, value in d.items():\n",
    "            # Accumulate the values for each key\n",
    "            result[key] = result.get(key, 0) + value\n",
    "            # Keep track of the counts for each key\n",
    "            counts[key] = counts.get(key, 0) + 1\n",
    "    \n",
    "    # Calculate the average for each key\n",
    "    for key in result:\n",
    "        result[key] /= counts[key]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a532e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0            0                   0          0         0  \\\n",
      "modelName  GaussianNB  BernoulliNB  LogisticRegression  SVClinear    SVCrbf   \n",
      "CapP         0.688442     0.882649            0.895849   0.821625  0.839716   \n",
      "CapR              1.0     0.789781            0.751825   0.832117  0.870073   \n",
      "CapF1        0.815476     0.833595            0.817488   0.826565  0.854544   \n",
      "HGP               0.0     0.094848            0.135714   0.080404  0.166667   \n",
      "HGR               0.0        0.125               0.225        0.1      0.05   \n",
      "HGF1              0.0     0.105835            0.169091   0.089026  0.076364   \n",
      "SGP               0.0     0.516725            0.505804   0.518816  0.568514   \n",
      "SGR               0.0     0.672222            0.672222   0.516667  0.694444   \n",
      "SGF1              0.0     0.583109            0.576993   0.515718   0.62415   \n",
      "TP                0.0     0.475529            0.441225   0.505244  0.580606   \n",
      "TR                0.0     0.555556            0.611111   0.455556  0.366667   \n",
      "TF1               0.0     0.509945            0.511658   0.476499  0.438855   \n",
      "\n",
      "                  0           0                       0              0  \n",
      "modelName   SVCpoly  SVCsigmoid  RandomForestClassifier  MLPClassifier  \n",
      "CapP       0.820294    0.884519                0.783742       0.828761  \n",
      "CapR       0.916788    0.681752                0.883212       0.855474  \n",
      "CapF1      0.865762    0.769871                0.830435       0.841637  \n",
      "HGP        0.166667    0.107677                     0.0       0.068571  \n",
      "HGR            0.05       0.275                     0.0           0.05  \n",
      "HGF1       0.076364    0.154302                     0.0       0.057436  \n",
      "SGP        0.625276    0.439472                0.499459       0.522587  \n",
      "SGR        0.605556    0.527778                     0.5           0.55  \n",
      "SGF1       0.613938    0.478732                0.497977       0.534628  \n",
      "TP         0.599068     0.37342                0.433089       0.541667  \n",
      "TR         0.311111    0.644444                     0.2       0.444444  \n",
      "TF1        0.399844    0.471142                 0.26476       0.486716  \n",
      "Save to File!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Create 5 Folds \n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "svm_linear = svm.SVC(C=10, class_weight='balanced', kernel='linear', random_state=0)\n",
    "svm_poly = svm.SVC(C=1, class_weight='balanced', degree=2, kernel='poly', random_state=0)\n",
    "svm_rbf = svm.SVC(C=1, class_weight='balanced', kernel='rbf', random_state=0)\n",
    "svm_sigmoid = svm.SVC(C=1, class_weight='balanced', kernel='sigmoid', random_state=0)\n",
    "rf = RandomForestClassifier(class_weight='balanced', max_depth=25, criterion = 'entropy', random_state=0)\n",
    "nb_Ber = naive_bayes.BernoulliNB(alpha=0.1, binarize=0)\n",
    "nb_Gau = naive_bayes.GaussianNB(var_smoothing=0)\n",
    "lr = LogisticRegression(C=1, class_weight='balanced', solver='newton-cholesky', random_state=0)\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=25,solver='lbfgs', learning_rate='constant', alpha=0.0001, random_state=0)\n",
    "\n",
    "\n",
    "models = [nb_Gau, nb_Ber, lr, svm_linear, svm_rbf,svm_poly, svm_sigmoid, rf, mlp]\n",
    "# models = [mlp]\n",
    "results_df = pd.DataFrame()\n",
    "for model in models:\n",
    "    results = []\n",
    "    \n",
    "    for train_index, test_index in sss.split(features, labels['Label']):    \n",
    "        x_vec_train, x_vec_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels['Label'][train_index], labels['Label'][test_index] \n",
    "        \n",
    "        model.fit(x_vec_train.toarray(), y_train)\n",
    "        y_pred = model.predict(x_vec_test.toarray())\n",
    "        results.append(evaluation(y_test, y_pred, target_names=target_names))\n",
    "        \n",
    "    # print(type(pd.DataFrame(results).mean()))\n",
    "    if type(model).__name__ == \"SVC\": \n",
    "        name = pd.DataFrame({'modelName': [type(model).__name__ + model.kernel]})\n",
    "    else: name = pd.DataFrame({'modelName': [type(model).__name__]})\n",
    "    model_results_df = pd.concat([name.T, pd.DataFrame(results).mean()])\n",
    "    results_df = pd.concat([results_df, model_results_df], axis=1)\n",
    "print(results_df)\n",
    "\n",
    "print('Save to File!')\n",
    "results_df.to_excel('results/pipeline1_classical_ml_tf_idf.xlsx')\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3425b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_excel()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
